{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nukaraju2003/Python_practice/blob/master/Eng_Audio_to_telu_text_and_audio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqIR8DdXtT_5",
        "outputId": "27fb6992-ddf1-4d3e-b34b-a96820efcf2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-iz30qnce\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-iz30qnce\n",
            "  Resolved https://github.com/openai/whisper.git to commit 90db0de1896c23cbfaf0c58bc2d30665f709f170\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.60.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (1.26.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (4.67.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (10.5.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (0.8.0)\n",
            "Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20240930) (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper==20240930) (3.16.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20240930) (0.43.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20240930) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20240930) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper==20240930) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20240930) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20240930) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJG6eyZftcgd",
        "outputId": "1df0730c-7962-45e2-c6f7-8c6391c4498d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import whisper\n",
        "import warnings\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, MarianMTModel, MarianTokenizer\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "4fkVlFiztlbW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the Whisper model (choose 'small', 'medium', or 'large' for better accuracy)\n",
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "PdGVlMFutwJg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Translation models and tokenizers setup\n",
        "nllb_model_name = \"facebook/nllb-200-distilled-1.3B\"\n",
        "nllb_tokenizer = AutoTokenizer.from_pretrained(nllb_model_name)\n",
        "nllb_model = AutoModelForSeq2SeqLM.from_pretrained(nllb_model_name)"
      ],
      "metadata": {
        "id": "8VX2toJct42v"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to split long text into chunks\n",
        "def split_text_into_chunks(text, max_tokens, tokenizer):\n",
        "    tokens = tokenizer.encode(text)\n",
        "    chunks = []\n",
        "    for i in range(0, len(tokens), max_tokens):\n",
        "        chunk_tokens = tokens[i:i + max_tokens]\n",
        "        chunks.append(tokenizer.decode(chunk_tokens, skip_special_tokens=True))\n",
        "    return chunks"
      ],
      "metadata": {
        "id": "8nVBMY1Pj4ON"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Helper function to translate chunks of text\n",
        "def translate_chunks(chunks, translation_function):\n",
        "    translated_chunks = [translation_function(chunk) for chunk in chunks]\n",
        "    return \" \".join(translated_chunks)"
      ],
      "metadata": {
        "id": "qT42PY7Lj6un"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrapper function for large text translation\n",
        "def translate_large_text(text, translation_function, tokenizer, max_tokens=512):\n",
        "    chunks = split_text_into_chunks(text, max_tokens, tokenizer)\n",
        "    translated_text = translate_chunks(chunks, translation_function)\n",
        "    return translated_text"
      ],
      "metadata": {
        "id": "YtUSsqDEkBvX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def english_to_telugu(text):\n",
        "    src_lang = \"eng_Latn\"\n",
        "    tgt_lang = \"tel_Telu\"\n",
        "    nllb_tokenizer.src_lang = src_lang\n",
        "    inputs = nllb_tokenizer(text, return_tensors=\"pt\", padding=True)\n",
        "    outputs = nllb_model.generate(**inputs, forced_bos_token_id=nllb_tokenizer.convert_tokens_to_ids(tgt_lang))\n",
        "    return nllb_tokenizer.decode(outputs[0], skip_special_tokens=True)"
      ],
      "metadata": {
        "id": "4IwXaML8uGKH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate gTTS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wVTlHStEhRFE",
        "outputId": "08465e70-c9ac-44d4-ddc9-a838af2e36f7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (1.2.1)\n",
            "Requirement already satisfied: gTTS in /usr/local/lib/python3.10/dist-packages (2.5.4)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.5.1+cu121)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.27.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.5)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from gTTS) (2.32.3)\n",
            "Requirement already satisfied: click<8.2,>=7.1 in /usr/local/lib/python3.10/dist-packages (from gTTS) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.10.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->gTTS) (2024.12.14)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gtts\n",
        "import gtts\n",
        "from gtts import gTTS\n",
        "\n",
        "def text_to_speech(text, lang, filename_prefix=\"audio\"):\n",
        "    \"\"\"Converts text to speech using gTTS and saves it as an MP3 file.\n",
        "\n",
        "    Args:\n",
        "        text (str): Text to convert to speech.\n",
        "        lang (str): Language code (e.g., 'en', 'te').\n",
        "\n",
        "    Returns:\n",
        "        str: Filename of the generated audio file.\n",
        "    \"\"\"\n",
        "    # gTTS expects language codes like 'en', 'te', etc.\n",
        "    # Mapping 'tel' to 'te' for Telugu\n",
        "    lang_mapping = {\n",
        "        'tel': 'te'\n",
        "    }\n",
        "    lang = lang_mapping.get(lang, lang) # Get mapped value or keep original if not found\n",
        "\n",
        "    tts = gTTS(text=text, lang=lang)\n",
        "    filename = f\"/content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/{filename_prefix}_audio.mp3\"\n",
        "    tts.save(filename)\n",
        "    return filename"
      ],
      "metadata": {
        "id": "4wqFNf0oKlCI"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_and_translate(audio_path, model, translate_large_text, tokenizer, target_lang_code='tel_Telu'):\n",
        "    \"\"\"Transcribes an audio file and translates the text to a target language.\n",
        "\n",
        "    Args:\n",
        "        audio_path (str): Path to the audio file.\n",
        "        model (whisper.Whisper): The Whisper model to use for transcription.\n",
        "        translate_large_text (function): The function to use for large text translation.\n",
        "        tokenizer (transformers.PreTrainedTokenizer): The tokenizer to use for translation.\n",
        "        target_lang_code (str, optional): The target language code (e.g., 'tel_Telu'). Defaults to 'tel_Telu'.\n",
        "    \"\"\"\n",
        "    # Step 1: Transcribe the audio file\n",
        "    print(\"Transcribing audio...\")\n",
        "    result = model.transcribe(audio_path)\n",
        "    transcribed_text = result[\"text\"]\n",
        "    print(\"Transcription Complete!\")\n",
        "    print(\"Transcribed Text:\", transcribed_text)\n",
        "\n",
        "    # Step 2: Translate the text\n",
        "    translated_text = translate_large_text(transcribed_text, english_to_telugu, tokenizer)\n",
        "    print(\"Translated Text:\")\n",
        "    print(translated_text)\n",
        "\n",
        "    # Step 3: Perform Text-to-Speech for English\n",
        "    english_audio_filename = text_to_speech(transcribed_text, 'en', filename_prefix=\"english\")\n",
        "    print(\"English audio saved to:\", english_audio_filename)\n",
        "\n",
        "    # Step 4: Perform Text-to-Speech for Telugu\n",
        "    telugu_audio_filename = text_to_speech(translated_text, target_lang_code[:3], filename_prefix=\"telugu\")\n",
        "    print(\"Telugu audio saved to:\", telugu_audio_filename)\n",
        "\n",
        "    return translated_text, english_audio_filename, telugu_audio_filename"
      ],
      "metadata": {
        "id": "FvNE4CmbJ0uK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a2ywtxFN8Aq",
        "outputId": "1ea81848-9fbe-4897-d47c-d25a557c918a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the audio file path\n",
        "audio_path = \"/content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/audio.wav\"  # Replace with your file path"
      ],
      "metadata": {
        "id": "n-T5gj3gviEz"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(audio_path)"
      ],
      "metadata": {
        "id": "6mB7D9FmUt3U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "faa4f749-9a5c-47d6-f478-980c0ee6baa7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/audio.wav\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the pipeline\n",
        "translated_text, english_audio_filename, telugu_audio_filename = transcribe_and_translate(audio_path, model, translate_large_text, nllb_tokenizer)"
      ],
      "metadata": {
        "id": "v7cIonnbvv_9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d024511f-b40e-4c15-9ebb-f07cebcdc8d5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transcribing audio...\n",
            "Transcription Complete!\n",
            "Transcribed Text:  Today I'm going to teach you one expression, just one, because I want you to memorize it and start using it every time you speak English. This expression is extremely useful and native speakers use it all the time. Every day we come across something that is very easy or obvious to do or understand. You don't even need to think about it. It's obvious that water is wet, then the sun is hot. And it's obvious that a cat will always land on its feet. Try your own risk. So when you don't have to consider something for a long time, it's just because it's a no-brainer. It's a no-brainer that you will improve your English if you follow me here.\n",
            "Translated Text:\n",
            "ఈ రోజు నేను మీకు ఒక వ్యక్తీకరణ నేర్పబోతున్నాను, ఒక్కటి మాత్రమే, ఎందుకంటే మీరు ఆంగ్లంలో మాట్లాడే ప్రతిసారీ దాన్ని గుర్తుంచుకోవాలని మరియు ఉపయోగించడం ప్రారంభించాలని నేను కోరుకుంటున్నాను. ఈ వ్యక్తీకరణ చాలా ఉపయోగకరంగా ఉంటుంది మరియు స్థానిక మాట్లాడేవారు దీన్ని అన్ని సమయాలలో ఉపయోగిస్తారు. ప్రతిరోజూ మనం చేయటానికి లేదా అర్థం చేసుకోవడానికి చాలా సులభం లేదా స్పష్టంగా ఉన్నదాన్ని ఎదుర్కొంటాము. మీరు దాని గురించి ఆలోచించాల్సిన అవసరం లేదు. నీరు తడిగా ఉందని స్పష్టంగా ఉంది, అప్పుడు సూర్యుడు వేడిగా ఉన్నాడు. మరియు పిల్లి ఎల్లప్పుడూ తన పాదాలపై భూమికి వస్తుంది. మీ స్వంత ప్రమాదాన్ని ప్రయత్నించండి. కాబట్టి మీరు ఏదో ఎక్కువ కాలం పరిగణించాల్సిన అవసరం లేనప్పుడు, అది సహజమైనది. మీరు ఇక్కడ నన్ను అనుసరించినట్లయితే మీ ఇంగ్లీష్ మెరుగుపరుస్తుంది.\n",
            "English audio saved to: /content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/english_audio.mp3\n",
            "Telugu audio saved to: /content/drive/MyDrive/My Projects/Trizen/CBPT1SGA/telugu_audio.mp3\n"
          ]
        }
      ]
    }
  ]
}